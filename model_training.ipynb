{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d9eeb49",
   "metadata": {},
   "source": [
    "## Import các thư viện cần thiết"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95a1dcc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\scipy\\__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.26.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "# Import các thư viện cần thiết\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e986a6",
   "metadata": {},
   "source": [
    "## Chuẩn bị dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbe850ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>aqi</th>\n",
       "      <th>co</th>\n",
       "      <th>no</th>\n",
       "      <th>no2</th>\n",
       "      <th>o3</th>\n",
       "      <th>so2</th>\n",
       "      <th>pm2_5</th>\n",
       "      <th>pm10</th>\n",
       "      <th>nh3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-01 00:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>700.95</td>\n",
       "      <td>0.44</td>\n",
       "      <td>35.99</td>\n",
       "      <td>17.35</td>\n",
       "      <td>32.90</td>\n",
       "      <td>20.33</td>\n",
       "      <td>26.64</td>\n",
       "      <td>8.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-01 01:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>847.82</td>\n",
       "      <td>2.46</td>\n",
       "      <td>38.04</td>\n",
       "      <td>18.06</td>\n",
       "      <td>36.24</td>\n",
       "      <td>23.32</td>\n",
       "      <td>30.54</td>\n",
       "      <td>9.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-01 02:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>894.55</td>\n",
       "      <td>5.25</td>\n",
       "      <td>38.39</td>\n",
       "      <td>23.25</td>\n",
       "      <td>41.01</td>\n",
       "      <td>24.16</td>\n",
       "      <td>31.93</td>\n",
       "      <td>9.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-01-01 03:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>827.79</td>\n",
       "      <td>6.20</td>\n",
       "      <td>36.33</td>\n",
       "      <td>33.98</td>\n",
       "      <td>43.39</td>\n",
       "      <td>23.20</td>\n",
       "      <td>30.91</td>\n",
       "      <td>8.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-01-01 04:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>660.90</td>\n",
       "      <td>3.69</td>\n",
       "      <td>29.13</td>\n",
       "      <td>54.36</td>\n",
       "      <td>35.76</td>\n",
       "      <td>19.50</td>\n",
       "      <td>25.60</td>\n",
       "      <td>6.21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    dt  aqi      co    no    no2     o3    so2  pm2_5   pm10  \\\n",
       "0  2021-01-01 00:00:00    3  700.95  0.44  35.99  17.35  32.90  20.33  26.64   \n",
       "1  2021-01-01 01:00:00    3  847.82  2.46  38.04  18.06  36.24  23.32  30.54   \n",
       "2  2021-01-01 02:00:00    3  894.55  5.25  38.39  23.25  41.01  24.16  31.93   \n",
       "3  2021-01-01 03:00:00    3  827.79  6.20  36.33  33.98  43.39  23.20  30.91   \n",
       "4  2021-01-01 04:00:00    2  660.90  3.69  29.13  54.36  35.76  19.50  25.60   \n",
       "\n",
       "    nh3  \n",
       "0  8.99  \n",
       "1  9.37  \n",
       "2  9.25  \n",
       "3  8.61  \n",
       "4  6.21  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Đọc dữ liệu từ file CSV\n",
    "data = pd.read_csv('./Data/air_quality_cleaned.csv')\n",
    "\n",
    "# Xem mẫu dữ liệu\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddbaaf32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25176 entries, 0 to 25175\n",
      "Data columns (total 10 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   dt      25176 non-null  object \n",
      " 1   aqi     25176 non-null  int64  \n",
      " 2   co      25176 non-null  float64\n",
      " 3   no      25176 non-null  float64\n",
      " 4   no2     25176 non-null  float64\n",
      " 5   o3      25176 non-null  float64\n",
      " 6   so2     25176 non-null  float64\n",
      " 7   pm2_5   25176 non-null  float64\n",
      " 8   pm10    25176 non-null  float64\n",
      " 9   nh3     25176 non-null  float64\n",
      "dtypes: float64(8), int64(1), object(1)\n",
      "memory usage: 1.9+ MB\n"
     ]
    }
   ],
   "source": [
    "# Kiểm tra thông tin cơ bản về dữ liệu\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2cde180",
   "metadata": {},
   "source": [
    "## Huấn luyện mô hình"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0836d1",
   "metadata": {},
   "source": [
    "**Lựa chọn thuộc tính:** chúng em sẽ tiến hành phân loại chất lượng không khí theo chỉ số `aqi` dựa trên các chỉ số `no, co, so2, no2, o3, pm2_5, pm10, nh3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26cffd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chia dữ liệu thành features (X) và target variable (y)\n",
    "X = data[['no', 'co', 'so2', 'no2', 'o3', 'pm2_5', 'pm10', 'nh3']]  # Chọn các chỉ số khí quyển làm features\n",
    "y = data['aqi']  # Chọn cột AQI làm target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7bd8abb",
   "metadata": {},
   "source": [
    "**Feature Scaling:**\n",
    "\n",
    "- Khi khoảng giá trị giữa 2 thuộc tính quá cách xa nhau thì việc mô hình hóa cũng như trực quan mối quan hệ có thể gặp khó khăn, do đó phải thực hiện kĩ thuật 'Feature Scaling' hay việt hóa là 'Co giãn thuộc tính'.\n",
    "- Có 3 phương pháp feature scaling chính là:\n",
    "    - Standardisation (Chính quy hóa): Làm cho tập dữ liệu có trung bình là 0 và độ lệch chuẩn là 1 và được áp dụng cho hầu hết các trường hợp cần feature scaling.\n",
    "    - Normalisation (Tiêu chuẩn hóa): Làm cho các giá trị trong tập dữ liệu thuộc đoạn [0, 1] và được áp dụng nếu tập dữ liệu tuân theo phân phối chuẩn.\n",
    "    - MinMax Scaler: Đưa các giá trị về khoảng giữa 2 giá trị min và max trong miền giá trị của thuộc tính, có thể là đoạn [-1, 0], [0, 1], [-1, 1],...\n",
    "- Trong bài này nhóm chọn phương pháp Standardisation để scaling khoảng giá trị của thuộc tính về khoảng gần hơn với giá trị của tập y là `aqi`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "264d8622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chuẩn hóa dữ liệu\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e173dee0",
   "metadata": {},
   "source": [
    "**Phân tách bộ dữ liệu thành 3 tập training set, validation set và test set:**\n",
    "\n",
    "- Mục đích:\n",
    "    - Huấn luyện và đánh giá độc lập: Tập huấn luyện được sử dụng để huấn luyện mô hình. Tập kiểm tra được sử dụng để đánh giá hiệu suất tổng quát của mô hình. Dữ liệu này không được sử dụng trong quá trình huấn luyện để đảm bảo mô hình có khả năng tổng quát hóa với dữ liệu mới, đảm bảo tính khách quan.\n",
    "    - Kiểm tra: Tập validation được sử dụng để tìm ra mô hình tốt nhất với những siêu tham số khác nhau.\n",
    "    - Tránh overfitting: Nếu không chia dữ liệu mà sử dụng toàn bộ dữ liệu để huấn luyện, mô hình có thể học \"quá khớp\" (overfit) dữ liệu huấn luyện mà không tổng quát hóa được cho dữ liệu mới. Việc có tập kiểm tra giúp đánh giá xem mô hình có đang học từ dữ liệu một cách tổng quát hay chỉ học \"nhớ\" dữ liệu huấn luyện không.\n",
    "    - Đánh giá và cải thiện mô hình: Thông qua việc đánh giá trên tập kiểm tra, chúng ta có thể đánh giá hiệu suất của mô hình và cải thiện nó thông qua việc điều chỉnh các tham số hoặc phương pháp huấn luyện.\n",
    "- Kích thước mỗi tập như sau:\n",
    "    - Size of Training set = 80% * (Size of Dataset)\n",
    "    - Size of Test set = 20% * (Size of Dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0118cda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chia dữ liệu thành tập train và tập test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Tiếp tục chia tập train thành tập train và tập validation\n",
    "#X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)  # 0.25 x 0.8 = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451c8e8f",
   "metadata": {},
   "source": [
    "### 1. Mô hình Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39467046",
   "metadata": {},
   "source": [
    "- Mô hình Decision Tree (cây quyết định) là một thuật toán học máy có cấu trúc dạng cây, chia dữ liệu dựa trên các quy tắc quyết định đơn giản. Mỗi nút lá của cây đại diện cho một nhãn hoặc một giá trị dự đoán, trong khi các nút gốc và nội bộ biểu diễn các quy tắc quyết định để chia tách dữ liệu.\n",
    "\n",
    "- Cách hoạt động chính của Decision Tree:\n",
    "\n",
    "    - Chọn thuộc tính quan trọng: Các thuộc tính được chọn dựa trên độ quan trọng của chúng trong việc chia dữ liệu.\n",
    "    - Tách nút (node splitting): Mỗi nút trong cây đại diện cho một thuộc tính và một ngưỡng (threshold). Dữ liệu được chia thành các nhánh dựa trên giá trị của thuộc tính này.\n",
    "    - Xây dựng cây: Quá trình tách nút được thực hiện đệ quy cho đến khi một điều kiện dừng được đáp ứng (như đạt đến độ sâu tối đa hoặc không thể chia tách thêm)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61407902",
   "metadata": {},
   "source": [
    "**Tiến hành huấn luyện:**\n",
    "\n",
    "- Đầu tiên, Nhóm tiến hành mô hình hóa dữ liệu theo *Decision Tree* với một cây khá đơn giản dựa theo thuật toán đo lường *Gini*, *độ sâu tối đa của cây* là 3, *số mẫu tối thiểu cần thiết để chia một node* là 2 và *số mẫu tối thiểu cần thiết ở mỗi leaf* là 1. \n",
    "- Sau đó đánh giá mô hình này dựa trên *Cross-validation* bằng cách chia tập train thành 5 phần bằng nhau và sử dụng 4 phần để huấn luyện và phần còn lại để đánh giá mô hình, quá trình này được lặp lại 5 lần, mỗi lần sử dụng một fold khác nhau làm tập kiểm tra. Điều này nhằm thử nghiệm tính hiệu quả của cây đơn giản này với bộ dữ liệu mà chúng em có.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54a59bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Scores: [0.80635551 0.81330685 0.80685204 0.80983118 0.80362463]\n",
      "Mean CV Accuracy: 0.8079940417080437\n",
      "Test Accuracy: 0.8105639396346307\n"
     ]
    }
   ],
   "source": [
    "# Khởi tạo mô hình Decision Tree\n",
    "model = DecisionTreeClassifier(criterion='gini', max_depth=3, min_samples_split=2, min_samples_leaf=1)\n",
    "\n",
    "# Huấn luyện mô hình trên tập train\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Đánh giá mô hình trên tập validation\n",
    "#val_accuracy = model.score(X_val, y_val)\n",
    "#print(f'Validation Accuracy: {val_accuracy}')\n",
    "\n",
    "# Đánh giá mô hình bằng cross-validation trên tập train\n",
    "cv_scores = cross_val_score(model, X_train, y_train, cv=5)\n",
    "print(\"Cross-Validation Scores:\", cv_scores)\n",
    "print(\"Mean CV Accuracy:\", cv_scores.mean())\n",
    "\n",
    "# Đánh giá mô hình trên tập test (đánh giá cuối cùng)\n",
    "test_accuracy = model.score(X_test, y_test)\n",
    "print(f'Test Accuracy: {test_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ce0ac1",
   "metadata": {},
   "source": [
    "**Đánh giá:**\n",
    "\n",
    "- Có thể thấy việc chia tập train thành 4 fold và sử dụng Cross-Validation cho ra hiệu quả khá tương đồng nhau (Trung bình xấp xỉ 80%). Hiệu quả trên tập test ban đầu cũng khá tương tự như vậy (Xấp xỉ 81%). Kết quả này là khá cao, như vậy ta có thể thấy mô hình này khá hiệu quả."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f76c10",
   "metadata": {},
   "source": [
    "**Cải thiện mô hình:**\n",
    "- Mô hình có thể cho ra những kết quả tốt hơn với những tham số khác, vì vậy ta có thể kiểm tra thông qua thư viện `GridSearchCV`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c515d8cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'criterion': 'gini', 'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 2}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Sử dụng cách chia tập train và tập test lần lượt là 80% và 20% của dataset, sau đó cũng sử dụng Cross-validation chia tập train thành 4 fold như trên\n",
    "\"\"\"\n",
    "\n",
    "# Chia dữ liệu thành tập train và tập test\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Khởi tạo mô hình Decision Tree\n",
    "dtree = DecisionTreeClassifier()\n",
    "\n",
    "# Định nghĩa lưới các giá trị tham số cần tìm kiếm\n",
    "param_grid = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [3, 5, 10, 15, 20],\n",
    "    'min_samples_split': [2, 3, 5, 7, 10],\n",
    "    'min_samples_leaf': [1, 2, 3, 4, 5]\n",
    "}\n",
    "\n",
    "# Tạo đối tượng GridSearchCV\n",
    "grid_search = GridSearchCV(dtree, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Thực hiện tìm kiếm trên lưới tham số\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# In ra tham số tốt nhất\n",
    "print(\"Best Parameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5602ecf0",
   "metadata": {},
   "source": [
    "Như vậy ta đã có thông số params tốt nhất có thể tìm được trong tập các params đưa ra như trên, ta sẽ lưu lại thành `best_model` và đánh giá nó"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "929a5e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8387609213661636\n"
     ]
    }
   ],
   "source": [
    "# Đánh giá hiệu suất của mô hình tốt nhất trên tập kiểm tra\n",
    "best_model_tree = grid_search.best_estimator_\n",
    "y_pred = best_model_tree.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Test Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c61913b",
   "metadata": {},
   "source": [
    "**Dự đoán:**\n",
    "- Tiến hành dự đoán từ 1 sample data với `best_model` vừa tạo ra như trên"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f6e4a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted AQI: [2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names must be in the same order as they were in fit.\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Tạo sample data mới\n",
    "new_data = {\n",
    "    'no': 0.5,\n",
    "    'co': 700.3,\n",
    "    'no2': 37.3,\n",
    "    'o3': 52.7,\n",
    "    'so2': 35.1,\n",
    "    'pm2_5': 19.5,\n",
    "    'pm10': 20.2,\n",
    "    'nh3': 7.99\n",
    "}\n",
    "\n",
    "# Chuyển sample data thành Dataframe\n",
    "new_df = pd.DataFrame([new_data])\n",
    "\n",
    "# Chuẩn hóa sample data\n",
    "new_sample = scaler.transform(new_df)\n",
    "\n",
    "# Dữ đoán aqi sử dụng best_model vừa huấn luyện trên \n",
    "predicted_aqi = best_model_tree.predict(new_sample)\n",
    "\n",
    "print(f'Predicted AQI: {predicted_aqi}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ac29c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
